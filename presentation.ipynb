{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Acoustic Handwriting Recognition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import numpy as np\n",
      "import matplotlib.pylab as plt\n",
      "import nltk\n",
      "import sys\n",
      "\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.grid_search import RandomizedSearchCV\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from scipy import stats\n",
      "\n",
      "import utils\n",
      "import pickle\n",
      "from classifier import SoundClassifier\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Set parameters: number of K-Means centroids, number of patches to extract per sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "USE_PCA = False\n",
      "NUM_CHARS = 30\n",
      "PER_CLASS = 50\n",
      "PATCH_TYPES = 120\n",
      "N_PATCHES = 120\n",
      "SEED = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load data{k: len(data_dict[k]) for k in ordered_keys}\n",
      "DATA_DIR = \"./data/s1\"\n",
      "data_dict = utils.load_data(DATA_DIR)\n",
      "ordered_keys = sorted(data_dict.keys())\n",
      "\n",
      "cm_predictions = []\n",
      "cm_labels = []\n",
      "\n",
      "# Flatten out dictionary to example (X) and label (Y) arrays\n",
      "X = []\n",
      "Y = []\n",
      "for key in ordered_keys[:NUM_CHARS]:\n",
      "    for example in data_dict[key][:PER_CLASS]:\n",
      "        X.append(example)\n",
      "        Y.append(key)\n",
      "X = np.array(X)\n",
      "Y = np.array(Y)\n",
      "print {k: len(data_dict[k]) for k in ordered_keys}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'A': 51, 'C': 50, 'B': 55, 'E': 51, 'D': 51, 'G': 52, 'F': 52, 'I': 52, 'H': 54, 'K': 52, 'J': 51, 'M': 53, 'L': 51, 'O': 53, 'N': 50, 'Q': 53, 'P': 52, 'S': 53, 'R': 54, 'U': 53, 'T': 54, 'W': 52, 'V': 54, 'Y': 53, 'X': 55, 'Z': 56}\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Test/Train split - 45 training examples, 5 test per sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train, test = list(StratifiedShuffleSplit(Y, n_iter=1, test_size=0.1, random_state=SEED))[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training the classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SoundClassifier(patch_types=PATCH_TYPES, \n",
      "                      n_patches=N_PATCHES,\n",
      "                      use_pca=USE_PCA,\n",
      "                      verbose=True)\n",
      "clf.fit(X[train], Y[train])\n",
      "print \"Testing on training data......\", clf.score(X[train], Y[train])\n",
      "print \"Testing on unseen data...\", clf.score(X[test], Y[test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating windows...\n",
        "Clustering patches..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Creating histograms..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training classifier..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Testing on training data......"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "Testing on unseen data... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.792307692308\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x229d2d0>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing utils"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def s2i(s):\n",
      "    a = ord(min(clf.classifier.classes_))\n",
      "    return [ord(c) - a for c in s.upper() if str.isalpha(c)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.gutenberg.words('bible-kjv.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "['[', 'The', 'King', 'James', 'Bible', ']', 'The', ...]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = ''.join(s.upper() for s in nltk.corpus.gutenberg.words('bible-kjv.txt') if str.isalpha(s))\n",
      "#words = ''.join(s.upper() for s in \"my name is david dohan and the quick brown fox jumps over the lazy dog\" if str.isalpha(s))\n",
      "ints = s2i(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probabilities(corpus, alpha=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n",
      "    corpus = ''.join([c for c in corpus if c in alpha])\n",
      "    counts = [corpus.count(c) for c in alpha]\n",
      "    start_probs = np.array(counts, dtype=float) / sum(counts)\n",
      "    trans_counts = [[0.1 + corpus.count(\"%s%s\" % (a,b)) for b in alpha] for a in alpha]\n",
      "    trans_probs = np.array([np.array(x, dtype=float)/sum(x) for x in trans_counts])\n",
      "    return (start_probs, trans_probs)\n",
      "\n",
      "start_probs, trans_probs = get_probabilities(words, clf.classifier.classes_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Viterbi():\n",
      "    def __init__(self, start_probs, trans_probs):\n",
      "        self.trans_probs = np.array(trans_probs)\n",
      "        \n",
      "        # viterbi [t,i] is [probability of being at state i at time t | observations up to t, most likely previous state]\n",
      "        # -1 indicates no previous state\n",
      "        # t=1 indicates the first observation; t=0 indicates start probabilities\n",
      "        self.viterbi = [[[x,-1] for x in start_probs]]\n",
      "    \n",
      "    def observe(self, obs_probs):\n",
      "        # obs_props[i] == P(i|obs)\n",
      "        next_probs = [[0,-1]] * len(self.viterbi[-1])\n",
      "        \n",
      "        for i, (prob_at, _) in enumerate(self.viterbi[-1]):\n",
      "            for j, prob_to in enumerate(self.trans_probs[i,:]):\n",
      "                next_prob = prob_at * prob_to * obs_probs[j]\n",
      "                if next_prob > next_probs[j][0]:\n",
      "                    next_probs[j] = [next_prob, i]\n",
      "                    \n",
      "        # normalize\n",
      "        total = sum(x[0] for x in next_probs)\n",
      "        next_probs = [[i/total, j] for (i,j) in next_probs]\n",
      "        \n",
      "        self.viterbi.append(next_probs)\n",
      "        \n",
      "    def best_path(self):\n",
      "        path = []\n",
      "        \n",
      "        # Find the most recent node of the best path\n",
      "        count = -1 + len(self.viterbi)\n",
      "        i = np.argmax([p for (p,prev) in self.viterbi[count]])  # index of class\n",
      "        (prob, prev) = self.viterbi[count][i]\n",
      "        \n",
      "        while prev != -1:\n",
      "            count -= 1\n",
      "            path = [clf.classifier.classes_[i]] + path\n",
      "            \n",
      "            i = prev\n",
      "            (prob, prev) = self.viterbi[count][i]\n",
      "        \n",
      "        return path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_sentence(sequence):\n",
      "    sentence, seqs = utils.generate_sentence(Y[test], sequence)\n",
      "    seq = seqs[0]\n",
      "    print seq\n",
      "\n",
      "    print \"Actual         :\", ' '.join(Y[test[seq]])\n",
      "    print \"Old prediction :\", ' '.join(clf.predict(X[test[seq]]))\n",
      "\n",
      "    v = Viterbi(start_probs, trans_probs)\n",
      "    probs = clf.predict_proba(X[test[seq]])\n",
      "    for obs in probs:\n",
      "        v.observe(obs)\n",
      "\n",
      "    print \"With HMM:       \", ' '.join(v.best_path())\n",
      "    \n",
      "    ordered = [list(reversed(sorted(zip(prob, clf.classifier.classes_)))) for prob in probs]\n",
      "    \n",
      "    for i in range(5):\n",
      "        for prob in ordered:\n",
      "            print prob[i][1], ' ',\n",
      "        print ''\n",
      "    \n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Test sentences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"Hello\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[84, 66, 97, 73, 33]\n",
        "Actual         : H E L L O\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H E L D O\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E L L O\n",
        "H   E   L   D   O   \n",
        "D   D   I   K   C   \n",
        "E   H   K   H   A   \n",
        "C   I   E   A   S   \n",
        "J   L   H   F   E   \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x1724190>"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"Hello world\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[75, 125, 60, 60, 88, 26, 101, 59, 106, 67]\n",
        "Actual         : H E L L O W O R L D\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A E L L O Z O R L D\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E L L O W O R L D\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x2f6ba110>"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"Hello world\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[113, 56, 122, 97, 33, 1, 119, 124, 97, 38]\n",
        "Actual         : H E L L O W O R L D\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H E L L O W O R L D\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E L L O W O R L D\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x3c5ed2d0>"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"Hello world\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[19, 54, 73, 97, 33, 68, 9, 12, 97, 23]\n",
        "Actual         : H E L L O W O R L D\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H E D L O U O R L D\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E A L O W O R L E\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x3a097a90>"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"the quick brown fox jumps over the lazy dog\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[114, 19, 56, 25, 82, 118, 104, 17, 15, 124, 43, 64, 5, 46, 119, 34, 100, 89, 125, 86, 67, 119, 70, 35, 124, 114, 19, 56, 122, 28, 45, 0, 4, 43, 80]\n",
        "Actual         : T H E Q U I C K B R O W N F O X J U M P S O V E R T H E L A Z Y D O G\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "T H E Q U I C K B R O W C F O A J U J P S O V E R T H E L C Z Y K O G\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " T H E Q U I C K B R O W E F O F J U M P S O V E R T H E L A L Y D O F\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x421bd90>"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"the quick brown fox jumps over the lazy dog\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[117, 115, 95, 58, 41, 26, 104, 50, 77, 124, 47, 39, 109, 71, 119, 128, 129, 41, 40, 48, 110, 43, 70, 56, 69, 114, 115, 54, 122, 79, 45, 49, 4, 9, 30]\n",
        "Actual         : T H E Q U I C K B R O W N F O X J U M P S O V E R T H E L A Z Y D O G\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C H E Q U L C K B R O Z N F O X J U M P S O V E R T H E L A Z Y K O C\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " T H E Q U I C E B R O A N F O T J U M P S O V E R T H E L A N T E O F\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x229d210>"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"security\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[52, 54, 104, 41, 37, 76, 114, 3]\n",
        "Actual         : S E C U R I T Y\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "S E C U R H T Y\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " S E C U R I T Y\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x406c050>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"happy birthday\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[19, 79, 48, 86, 0, 36, 111, 37, 92, 113, 38, 83, 7]\n",
        "Actual         : H A P P Y B I R T H D A Y\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H A P P Y B I R T H D C Y\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H A P P Y B E R T H E C Y\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x228c790>"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"happy birthday\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[113, 105, 86, 93, 81, 15, 26, 101, 114, 108, 57, 83, 81]\n",
        "Actual         : H A P P Y B I R T H D A Y\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H C P C Y B L R T I E C Y\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E P A Y B E R T I D A Y\n",
        "H   A   P   C   Y   B   L   R   T   I   E   C   Y   \n",
        "J   C   O   A   X   C   I   X   X   T   D   A   X   \n",
        "M   S   C   S   I   X   H   C   Y   L   T   S   I   \n",
        "G   E   A   E   A   A   X   I   R   D   I   E   A   \n",
        "F   X   N   N   D   Q   D   A   S   Y   X   Q   D   \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x406c490>"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}