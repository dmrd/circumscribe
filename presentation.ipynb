{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Acoustic Handwriting Recognition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import numpy as np\n",
      "import matplotlib.pylab as plt\n",
      "import nltk\n",
      "import sys\n",
      "\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.grid_search import RandomizedSearchCV\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from scipy import stats\n",
      "\n",
      "import utils\n",
      "import pickle\n",
      "from classifier import SoundClassifier\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Set parameters: number of K-Means centroids, number of patches to extract per sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "USE_PCA = False\n",
      "NUM_CHARS = 30\n",
      "PER_CLASS = 50\n",
      "PATCH_TYPES = 120\n",
      "N_PATCHES = 120\n",
      "SEED = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load data{k: len(data_dict[k]) for k in ordered_keys}\n",
      "DATA_DIR = \"./data2\"\n",
      "data_dict = utils.load_data(DATA_DIR)\n",
      "ordered_keys = sorted(data_dict.keys())\n",
      "\n",
      "cm_predictions = []\n",
      "cm_labels = []\n",
      "\n",
      "# Flatten out dictionary to example (X) and label (Y) arrays\n",
      "X = []\n",
      "Y = []\n",
      "for key in ordered_keys[:NUM_CHARS]:\n",
      "    for example in data_dict[key][:PER_CLASS]:\n",
      "        X.append(example)\n",
      "        Y.append(key)\n",
      "X = np.array(X)\n",
      "Y = np.array(Y)\n",
      "print {k: len(data_dict[k]) for k in ordered_keys}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'A': 51, 'C': 50, 'B': 55, 'E': 51, 'D': 51, 'G': 52, 'F': 52, 'I': 52, 'H': 54, 'K': 52, 'J': 51, 'M': 53, 'L': 51, 'O': 53, 'N': 50, 'Q': 53, 'P': 52, 'S': 53, 'R': 54, 'U': 53, 'T': 54, 'W': 52, 'V': 54, 'Y': 53, 'X': 55, 'Z': 56}\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Test/Train split - 45 training examples, 5 test per sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train, test = list(StratifiedShuffleSplit(Y, n_iter=1, test_size=0.1, random_state=SEED))[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training the classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = pickle.load(open(\"./presentation_clf.pkl\", 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SoundClassifier(patch_types=PATCH_TYPES, \n",
      "                      n_patches=N_PATCHES,\n",
      "                      use_pca=USE_PCA,\n",
      "                      verbose=True)\n",
      "clf.fit(X[train], Y[train])\n",
      "print \"Testing on training data......\", clf.score(X[train], Y[train])\n",
      "print \"Testing on unseen data...\", clf.score(X[test], Y[test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating windows...\n",
        "Clustering patches..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Creating histograms..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training classifier..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Testing on training data......"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.999145299145\n",
        "Testing on unseen data... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.815384615385\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x10f617c90>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing utils"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def s2i(s):\n",
      "    a = ord(min(clf.classifier.classes_))\n",
      "    return [ord(c) - a for c in s.upper() if str.isalpha(c)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = ''.join(s.upper() for s in nltk.corpus.inaugural.raw() if str.isalpha(s))\n",
      "#words = ''.join(s.upper() for s in \"my name is david dohan and the quick brown fox jumps over the lazy dog\" if str.isalpha(s))\n",
      "ints = s2i(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_probabilities(corpus, alpha=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n",
      "    corpus = ''.join([c for c in corpus if c in alpha])\n",
      "    counts = [corpus.count(c) for c in alpha]\n",
      "    start_probs = np.array(counts, dtype=float) / sum(counts)\n",
      "    trans_counts = [[0.1 + corpus.count(\"%s%s\" % (a,b)) for b in alpha] for a in alpha]\n",
      "    trans_probs = np.array([np.array(x, dtype=float)/sum(x) for x in trans_counts])\n",
      "    return (start_probs, trans_probs)\n",
      "\n",
      "start_probs, trans_probs = get_probabilities(words, clf.classifier.classes_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Viterbi():\n",
      "    def __init__(self, start_probs, trans_probs):\n",
      "        self.trans_probs = np.array(trans_probs)\n",
      "        \n",
      "        # viterbi [t,i] is [probability of being at state i at time t | observations up to t, most likely previous state]\n",
      "        # -1 indicates no previous state\n",
      "        # t=1 indicates the first observation; t=0 indicates start probabilities\n",
      "        self.viterbi = [[[x,-1] for x in start_probs]]\n",
      "    \n",
      "    def observe(self, obs_probs):\n",
      "        # obs_props[i] == P(i|obs)\n",
      "        next_probs = [[0,-1]] * len(self.viterbi[-1])\n",
      "        \n",
      "        for i, (prob_at, _) in enumerate(self.viterbi[-1]):\n",
      "            for j, prob_to in enumerate(self.trans_probs[i,:]):\n",
      "                next_prob = prob_at * prob_to * obs_probs[j]\n",
      "                if next_prob > next_probs[j][0]:\n",
      "                    next_probs[j] = [next_prob, i]\n",
      "                    \n",
      "        # normalize\n",
      "        total = sum(x[0] for x in next_probs)\n",
      "        next_probs = [[i/total, j] for (i,j) in next_probs]\n",
      "        \n",
      "        self.viterbi.append(next_probs)\n",
      "        \n",
      "    def best_path(self):\n",
      "        path = []\n",
      "        \n",
      "        # Find the most recent node of the best path\n",
      "        count = -1 + len(self.viterbi)\n",
      "        i = np.argmax([p for (p,prev) in self.viterbi[count]])  # index of class\n",
      "        (prob, prev) = self.viterbi[count][i]\n",
      "        \n",
      "        while prev != -1:\n",
      "            count -= 1\n",
      "            path = [clf.classifier.classes_[i]] + path\n",
      "            \n",
      "            i = prev\n",
      "            (prob, prev) = self.viterbi[count][i]\n",
      "        \n",
      "        return path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_sentence(sequence):\n",
      "    sentence, seqs = generate_sentence(Y[test], sequence)\n",
      "    seq = seqs[0]\n",
      "    print seq\n",
      "\n",
      "    print \"Actual         :\", ' '.join(Y[test[seq]])\n",
      "    print \"Old prediction :\", ' '.join(clf.predict(X[test[seq]]))\n",
      "\n",
      "    v = Viterbi(start_probs, trans_probs)\n",
      "    probs = clf.predict_proba(X[test[seq]])\n",
      "    for obs in probs:\n",
      "        v.observe(obs)\n",
      "\n",
      "    print \"With HMM:       \", ' '.join(v.best_path())\n",
      "    \n",
      "    ordered = [list(reversed(sorted(zip(prob, clf.classifier.classes_)))) for prob in probs]\n",
      "    \n",
      "    for i in range(5):\n",
      "        for prob in ordered:\n",
      "            print prob[i][1], ' ',\n",
      "        print ''\n",
      "    \n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Test sentences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_sentence(test_labels, sentence, n=1):\n",
      "   characters = defaultdict(lambda: list())\n",
      "   for i, label in enumerate(test_labels):\n",
      "       characters[label].append(i)\n",
      "\n",
      "   sentence = ''.join(c.upper() for c in sentence if str.isalpha(c))\n",
      "   result = []\n",
      "   for i in range(n):\n",
      "       example = []\n",
      "       for c in sentence:\n",
      "           example.append(random.choice(characters[c]))\n",
      "       result.append(example)\n",
      "   return sentence, result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"Hello\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[84, 66, 24, 122, 33]\n",
        "Actual         : H E L L O\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A E L L P\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E L L P\n",
        "A   E   L   L   P   \n",
        "Z   D   H   I   O   \n",
        "F   G   I   E   N   \n",
        "D   F   K   H   A   \n",
        "H   J   D   C   C   \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x138ea72d0>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"Hello world\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[75, 125, 60, 60, 88, 26, 101, 59, 106, 67]\n",
        "Actual         : H E L L O W O R L D\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A E L L O Z O R L D\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E L L O W O R L D\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x2f6ba110>"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"Hello world\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[113, 56, 122, 97, 33, 1, 119, 124, 97, 38]\n",
        "Actual         : H E L L O W O R L D\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H E L L O W O R L D\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E L L O W O R L D\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x3c5ed2d0>"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"Hello world\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[19, 54, 73, 97, 33, 68, 9, 12, 97, 23]\n",
        "Actual         : H E L L O W O R L D\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H E D L O U O R L D\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E A L O W O R L E\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x3a097a90>"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"the quick brown fox jumps over the lazy dog\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[123, 19, 66, 14, 41, 126, 116, 78, 15, 124, 47, 90, 8, 71, 33, 128, 100, 89, 120, 48, 59, 43, 27, 66, 124, 114, 108, 54, 122, 44, 127, 81, 38, 47, 91]\n",
        "Actual         : T H E Q U I C K B R O W N F O X J U M P S O V E R T H E L A Z Y D O G\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "T H E Q U I C K B R O C N F P C J U M P C O V E R E H E L C Z Z I O G\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " T H E Q U I C K E R O F O F O N J U M P E O V E R E H E L I Z E I O F\n",
        "T   H   E   Q   U   I   C   K   B   R   O   W   N   F   P   D   J   U   M   P   C   O   V   E   R   L   H   E   L   C   Z   Z   I   O   G   \n",
        "X   I   D   C   W   Y   A   L   A   C   P   C   C   G   O   C   M   V   J   C   A   P   W   D   C   E   F   L   I   A   U   A   E   P   I   \n",
        "Y   L   G   A   Z   L   E   I   C   A   C   Z   A   J   N   A   V   M   H   A   E   N   U   G   A   I   D   I   E   E   W   D   T   C   L   \n",
        "A   D   F   N   V   H   K   D   E   E   A   A   E   A   A   E   Y   Y   W   O   B   A   C   F   E   A   G   D   H   N   M   H   D   A   D   \n",
        "I   F   J   Y   C   D   N   H   N   X   N   E   B   H   C   K   U   Z   F   N   N   C   Z   J   X   X   K   C   C   B   V   W   G   N   E   \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x138ea7ed0>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"the quick brown fox jumps over the lazy dog\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[75, 113, 54, 14, 61, 26, 104, 11, 2, 12, 43, 90, 109, 46, 47, 74, 100, 61, 120, 48, 67, 43, 70, 54, 37, 92, 108, 54, 99, 105, 127, 81, 63, 47, 91]\n",
        "Actual         : T H E Q U I C K B R O W N F O X J U M P S O V E R T H E L A Z Y D O G\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A H E Q U D C K B C O C C F O X J U M P S O V E R T H E L A Z Z D O G\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " T H E Q U L A K B E O F O F O N J U M P S O V E R T H E L I Z E D O F\n",
        "A   H   E   Q   U   D   C   K   B   R   O   W   C   F   O   X   J   U   M   P   S   O   V   E   R   T   H   E   L   A   Z   Z   D   O   G   \n",
        "C   F   L   C   C   K   A   A   A   C   P   C   N   G   P   Y   M   C   J   C   C   P   Q   L   C   X   F   L   H   T   U   A   E   P   I   \n",
        "F   L   I   A   A   I   E   C   C   E   N   Z   A   C   C   I   V   A   H   A   A   N   U   I   A   Y   D   I   I   Y   W   D   I   C   L   \n",
        "E   K   D   N   Z   L   N   L   Y   A   A   A   E   A   A   A   Y   Z   W   O   N   A   C   D   E   I   G   D   K   I   M   H   Y   A   D   \n",
        "D   M   C   Y   E   H   B   D   N   L   C   E   B   E   N   C   U   E   F   N   E   C   W   C   X   D   K   C   Y   X   V   W   H   N   E   \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x10f617510>"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"security\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[52, 54, 104, 41, 37, 76, 114, 3]\n",
        "Actual         : S E C U R I T Y\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "S E C U R H T Y\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " S E C U R I T Y\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x406c050>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"happy birthday\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[19, 79, 48, 86, 0, 36, 111, 37, 92, 113, 38, 83, 7]\n",
        "Actual         : H A P P Y B I R T H D A Y\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H A P P Y B I R T H D C Y\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H A P P Y B E R T H E C Y\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x228c790>"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"happy birthday\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[84, 79, 86, 86, 0, 15, 118, 37, 117, 113, 38, 105, 3]\n",
        "Actual         : H A P P Y B I R T H D A Y\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H A P P Y B I R T H D A Y\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H A P P Y B I R T H D A Y\n",
        "H   A   P   P   Y   B   I   R   T   H   D   A   Y   \n",
        "A   C   O   O   X   C   L   C   X   J   E   Y   R   \n",
        "C   X   C   C   R   X   D   A   R   L   I   X   X   \n",
        "L   Y   A   A   L   A   Y   S   A   M   T   T   L   \n",
        "Y   S   N   N   A   Q   X   E   C   F   Y   I   F   \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x112f98dd0>"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"hello my name is david dohan and i go to princeton letz trasdf stuffsd the hasmdmm shoulds break\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[84, 95, 99, 97, 43, 40, 49, 60, 83, 72, 95, 76, 52, 4, 79, 27, 126, 57, 57, 47, 113, 83, 60, 44, 5, 63, 118, 30, 33, 117, 47, 106, 12, 76, 60, 116, 35, 114, 43, 6, 99, 66, 75, 127, 92, 101, 105, 59, 23, 31, 20, 117, 42, 71, 46, 67, 4, 117, 84, 54, 113, 44, 52, 120, 57, 72, 40, 20, 113, 43, 61, 97, 4, 52, 2, 69, 54, 28, 17]\n",
        "Actual         : H E L L O M Y N A M E I S D A V I D D O H A N A N D I G O T O P R I N C E T O N L E T Z T R A S D F S T U F F S D T H E H A S M D M M S H O U L D S B R E A K\n",
        "Old prediction : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H E L L O M Y N C M E I S D A C I E E O H C N A N D I G O T O P R I N C E T O N L E T Z T R A S D F S T U F F S D T H E H A S M E M M S H O U L D S B R E A K\n",
        "With HMM:       "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " H E L L O M Y N A M E I S D A V I T I O H A N A N D I G O T O P R I N C E T O N L E T U T R A S D F S T U F F S D T H E H A S M E M M S H O U L D S B R E A K\n",
        "H   E   L   L   O   M   Y   N   C   M   E   I   S   D   A   W   I   E   E   O   H   C   N   A   N   D   I   G   O   T   O   P   R   I   N   C   E   T   O   N   L   E   T   Z   T   R   A   S   D   F   S   T   U   F   F   S   D   T   H   E   H   A   S   M   E   M   M   S   H   O   U   L   D   S   B   R   E   A   K   \n",
        "A   D   I   I   P   C   X   X   A   J   D   A   X   E   C   C   L   D   D   P   J   A   X   C   X   E   L   F   P   X   P   O   X   A   X   A   D   L   P   P   I   D   X   W   X   X   Y   R   I   V   R   X   W   G   G   R   E   X   A   L   J   C   X   J   D   J   C   R   J   P   W   I   E   X   C   X   L   Y   L   \n",
        "C   L   H   K   N   J   A   P   S   U   L   L   R   Y   X   U   Y   T   T   C   L   S   P   X   P   I   D   J   N   R   C   N   C   L   P   X   C   E   N   C   H   J   R   U   R   T   X   A   E   M   C   R   V   A   Y   X   Y   R   C   C   L   X   R   H   T   U   J   C   L   N   C   K   Y   R   A   Y   C   C   J   \n",
        "L   Y   K   C   X   G   T   C   E   V   Y   D   E   I   Y   V   E   I   I   A   M   E   C   Y   C   Y   Y   M   X   A   A   X   S   D   C   Y   A   X   X   X   K   F   A   M   I   S   T   C   Y   U   A   A   C   C   R   C   I   A   L   D   M   Y   E   G   I   V   G   A   M   X   A   C   I   E   S   S   D   X   D   \n",
        "Y   V   E   E   V   S   H   Y   Q   F   V   X   L   X   S   A   G   X   X   S   F   Q   Y   S   Y   T   X   H   V   C   S   S   Y   X   Y   S   K   R   V   S   E   G   C   V   Y   Y   I   X   F   G   X   C   M   Z   X   Y   X   C   Y   S   F   S   L   V   X   F   S   X   F   V   X   E   X   L   X   C   S   S   C   \n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x112f98e50>"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'test' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-d8e8fca2dc0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.score(X[test], Y[test])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "0.81538461538461537"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x138ea7a10>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([ array([ 0.00128174,  0.00125122,  0.0010376 , ...,  0.00045776,\n",
        "        0.00048828,  0.00045776]),\n",
        "       array([  2.44140625e-04,   3.05175781e-04,   3.05175781e-04, ...,\n",
        "        -5.49316406e-04,  -9.15527344e-05,   3.05175781e-04]),\n",
        "       array([ 0.00039673,  0.00021362,  0.00027466, ..., -0.00036621,\n",
        "       -0.00057983, -0.00079346]),\n",
        "       array([-0.00115967, -0.00115967, -0.0007019 , ..., -0.00131226,\n",
        "       -0.00119019, -0.00100708]),\n",
        "       array([-0.0010376 , -0.00128174, -0.00128174, ..., -0.00183105,\n",
        "       -0.00137329, -0.00106812]),\n",
        "       array([ -9.76562500e-04,  -5.18798828e-04,  -6.10351562e-05, ...,\n",
        "        -3.26538086e-03,  -3.20434570e-03,  -3.17382812e-03]),\n",
        "       array([-0.00311279, -0.00323486, -0.00314331, ...,  0.00097656,\n",
        "        0.00112915,  0.00112915]),\n",
        "       array([ 0.00109863,  0.00109863,  0.00112915, ...,  0.00271606,\n",
        "        0.00280762,  0.00302124]),\n",
        "       array([ 0.00317383,  0.0032959 ,  0.0032959 , ...,  0.0005188 ,\n",
        "        0.00027466,  0.00024414]),\n",
        "       array([ 0.0005188 ,  0.0005188 ,  0.00057983, ...,  0.00540161,\n",
        "        0.00549316,  0.00552368])], dtype=object)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentence(\"hello my name is david dohan and i go to princeton letz trasdf stuffsd the hasmdmm shoulds break\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}